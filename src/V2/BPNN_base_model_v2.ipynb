{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e9fa9-2385-4d0c-9800-2465943a717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "# #Lets see if tensorflow finds the GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "#import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dd3754-8d54-4947-a94c-ace684a94cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets see if it works\n",
    "tf.ones(1) + tf.ones(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f494a0-5c24-4fa3-8487-ea4e41006551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # for working with arrays and matrices\n",
    "import pandas as pd # for data manipulation and analysis\n",
    "import matplotlib.pyplot as plt # for data visualization\n",
    "import seaborn as sns # for data visualization\n",
    "import time # for time-related functions\n",
    "import random # for random number generation\n",
    "import cv2 # for computer vision and image processing tasks\n",
    "import datetime # for saving date and time information\n",
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "import h5py # for working with HDF5 (Hierarchical Data Format) files\n",
    "import boto3 # for working with Amazon Web Services (AWS)\n",
    "from pynwb import NWBHDF5IO # for working with Neurodata Without Border (NWB) files\n",
    "import fsspec \n",
    "from fsspec.implementations.cached import CachingFileSystem # library used for working with various file systems in Python.\n",
    "import requests \n",
    "import aiohttp # libraries which are used for making HTTP requests in Python.\n",
    "import os # OS module provides various operating system-related functions to the code\n",
    "# import csv # CSV module is used for working with CSV (Comma Separated Values) files in Python.\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "\n",
    "# used for splitting data into training and testing sets in Python.\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "# for generating a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "# # Classes and functions from the Keras library which is used for building and training deep learning models in Python.\n",
    "# from keras.models import load_model\n",
    "# from keras.models import model_from_json\n",
    "# from keras.utils import to_categorical\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dropout\n",
    "# from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# These import the Adam optimizer class and various other classes from the TensorFlow Keras library \n",
    "# which is a high-level neural networks API used for building and training deep learning models in Python.\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "\n",
    "\n",
    "# # Loading functions\n",
    "from load_calcium_video import load_video_data\n",
    "from pixel_values_normalization import normalize_video\n",
    "from align_behavior_to_calcium import align_files\n",
    "from class_balance import check_class_imbalance\n",
    "from model_architecture import construct_model\n",
    "from preprocessing_model import model_preprocessing\n",
    "from run_model import model_execution\n",
    "from save_model_info import save_training_info\n",
    "# from set_s3_connection import generate_s3_url\n",
    "from plots import plot_first_frames, plot_random_frames\n",
    "from send_email_when_code_is_run import send_email\n",
    "from class_balance import check_distribution_among_datasets\n",
    "\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "from ann_visualizer.visualize import ann_viz\n",
    "import importlib\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187288c-f135-4a6c-b2bb-6a99efbcb2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal:\n",
    "experiment_name = \"Building base model, turning-type labels, 20% val - 80% train\"\n",
    "experiment_ID = '2.5'\n",
    "%store experiment_ID\n",
    "comment = \"Building base model... \"+str(experiment_name)\n",
    "train_test_split_strategy = \"20% val - 80% train\"\n",
    "name = 'BPNN_base_v2'\n",
    "model_version = str(name)+'.1'\n",
    "# experiment_version = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a47a2-c628-4c1a-becd-93b57e61ffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the output directory\n",
    "output_dir = \"output_base\"\n",
    "\n",
    "# Check if the output directory already exists\n",
    "if not os.path.exists(output_dir):\n",
    "    # Create the output directory\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "    # Create the balance, accuracy, loss, and cm directories inside the output directory\n",
    "    os.mkdir(os.path.join(output_dir, \"balance\"))\n",
    "    os.mkdir(os.path.join(output_dir, \"accuracy\"))\n",
    "    os.mkdir(os.path.join(output_dir, \"loss\"))\n",
    "    os.mkdir(os.path.join(output_dir, \"cm\"))\n",
    "    os.mkdir(os.path.join(output_dir, \"architecture\"))\n",
    "    os.mkdir(os.path.join(output_dir, \"pickles\"))\n",
    "else:\n",
    "    print(f\"The directory {output_dir} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bbb015-8fad-45c2-9bc7-aadaea312cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_calcium_url = 'https://s3.ki.se/dmc-striatum-arrowmaze/processed-data/miniscope-recordings/export-to-nwb/animal3learnday11/20211028_181307_animal3learnday11.nwb?AWSAccessKeyId=5AMYRX4EUZ0MV0276K24&Signature=ZrARakl7KWzfF6vI2c3nx8uh%2FFo%3D&Expires=1681304429'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dd04e7-b5f2-43aa-8991-75c9f40ea6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parse animal and learning day information\n",
    "video_name = os.path.basename(os.path.dirname(urlparse(s3_calcium_url).path))\n",
    "print(video_name) # Output: animal1learnday1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68929428-c972-409b-863c-9713e01af392",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_data = load_video_data(s3_calcium_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227baf69-4cee-4ade-a55e-da76ee4afb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_frame = np.min(video_data, axis=0)\n",
    "video_data = video_data - min_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64121a3a-4579-465f-9128-03fbd002eb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = normalize_video(video_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd3c43e-813d-425b-a58b-d809c87984f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the video has been loaded correctly and normalized\n",
    "images[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3720ab1-5bd4-4d6d-8779-630727fe2fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the size of the calcium video dataset\n",
    "num_of_frames = images.shape[0]\n",
    "img_height = images.shape[1]\n",
    "img_width = images.shape[2]\n",
    "print(\"The number of video frames is \", num_of_frames, \" and the frame dimensions (height x width) are: \", img_height, \"X\", img_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970a6806-2d66-4a4d-b338-59c03a3daaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing bonsai data file.\n",
    "# CSV with additional data from the behavior box, such as reward deliveries. Also includes information needed for synchronizing the calcium and behavioral recordings.\n",
    "bonsai_data = pd.read_csv('/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/tmaze_2021-10-28T18_13_23.csv', header=None)\n",
    "# Segmentation of each frame into one behavior class.\n",
    "df_behavior = pd.read_hdf('/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211028_181307_animal3learnday11.h5', 'per_frame')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb44381e-1edb-479d-91d2-2160e91beea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_annotations, df_unique_states = align_files(bonsai_data, df_behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7736cbfb-513d-4882-869b-f942a91433e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_annotations_unique = df_new_annotations.unique()\n",
    "df_new_annotations_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62210f48-d94c-41a0-9c7b-3ce2361a732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts, total_counts = check_class_imbalance(df_new_annotations, experiment_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1492d31c-e756-4a42-ae53-81be1c39594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "channel_dimension = 1\n",
    "labels = df_new_annotations\n",
    "epochs = 20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b285e1a-090a-4938-b87f-1513bae21916",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fee864-472d-42f0-b0bd-42093394fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into training and validation sets\n",
    "split_index = int(0.2 * len(images))  # Index to split data\n",
    "val_images, train_images = images[:split_index], images[split_index:]\n",
    "val_labels, train_labels = labels[:split_index], labels[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fe1abc-0d24-430b-ac11-06ae499bed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_distribution_among_datasets(val_labels, experiment_ID, dataset_type = 'Validation_set')\n",
    "check_distribution_among_datasets(train_labels, experiment_ID, dataset_type = 'Training_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7bc058-182d-4e4d-990c-6c4b1e5e1451",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, val_images, train_labels, val_labels, num_classes = model_preprocessing(train_images, val_images, train_labels, val_labels, df_new_annotations_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e618063-1b99-4f3c-b157-eeff97e3b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the first 5 random images\n",
    "plot_first_frames(train_images, train_labels)\n",
    "plot_first_frames(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b67a54a-5457-4497-a61f-b712e2132c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_random_frames(train_images, train_labels)\n",
    "plot_random_frames(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e4b9b5-cb50-4463-9c11-82c75d8dff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "\n",
    "def base_model(num_classes, name, input_shape):\n",
    "    \n",
    "    model = Sequential(name=name)\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(units=128, activation='relu'))\n",
    "    model.add(Dense(units=num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e4ccc-a6c3-48e8-9c89-fa8592b62ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "import time # for time-related functions\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle\n",
    "import csv # CSV module is used for working with CSV (Comma Separated Values) files in Python.\n",
    "# from f1_score import f1_score\n",
    "import os\n",
    "\n",
    "def base_model_execution(base_params):    \n",
    "    \n",
    "    model = base_params['model']\n",
    "    tf = base_params['tf']\n",
    "    train_images = base_params['train_images']\n",
    "    train_labels = base_params['train_labels']\n",
    "    epochs = base_params['epochs']\n",
    "    batch_size = base_params['batch_size']\n",
    "    validation_data = base_params['validation_data']\n",
    "    val_images = base_params['val_images']\n",
    "    val_labels = base_params['val_labels']\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # f1_score = f1_score()\n",
    "    \n",
    "    print(\"Compiling model...\")\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.legacy.Adam(), metrics=['accuracy'])\n",
    "    \n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
    "    \n",
    "    \n",
    "    print(\"Running model. Go grab a coffee or smth.\")\n",
    "    history = model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, validation_data=validation_data, callbacks=[early_stopping]) \n",
    "    \n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    hours, remainder = divmod(execution_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    print(f\"Execution time: {int(hours)} hours, {int(minutes)} minutes, {int(seconds)} seconds\")\n",
    "\n",
    "    \n",
    "    dir_name = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/V2/output/pickles\"\n",
    "    model_save_name = 'BPNN_base_model_v1.h5'\n",
    "    print(\"Now saving model data to pickles. Please wait...\")\n",
    "    model.save(f\"{dir_name}/{model_save_name}.png\")\n",
    "    \n",
    "    dir_name_pickles = \"src/V2/output/pickels\"\n",
    "    # Save the history object to a pickle file\n",
    "    with open(os.path.join(dir_name, 'history.pkl'), 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    \n",
    "    with open(os.path.join(dir_name, 'train_images.pkl'), 'wb') as f:\n",
    "        pickle.dump(train_images, f)\n",
    "\n",
    "    with open(os.path.join(dir_name, 'val_images.pkl'), 'wb') as f:\n",
    "        pickle.dump(val_images, f)\n",
    "\n",
    "    with open(os.path.join(dir_name, 'train_labels.pkl'), 'wb') as f:\n",
    "        pickle.dump(train_labels, f)\n",
    "        \n",
    "    with open(os.path.join(dir_name, 'val_labels.pkl'), 'wb') as f:\n",
    "        pickle.dump(val_labels, f)\n",
    "        \n",
    "    print(\"Done!\")\n",
    "\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f6b699-f19d-434a-8907-54bd6671e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (img_height, img_width, channel_dimension)\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0591e23c-44a1-4956-a555-7815d680fe0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'base_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bac90dc-b33d-4563-8695-874bb8d72616",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = base_model(num_classes, name, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af8d8a-fb46-40d6-bee2-86f62f06f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_name = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/V2/output/architecture\"\n",
    "# plot_name = f\"{name}_architecture\"\n",
    "# ann_viz(base_model, view=True, filename=plot_name, title=\"CNN — \"+str(name)+\" — Simple Architecture\")\n",
    "# plot_path = os.path.join(dir_name, f\"{plot_name}.png\")\n",
    "# plot = plt.gcf()\n",
    "# plot.savefig(plot_path, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97759b0e-76f6-4793-a98a-8ccb2d252a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data=(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91809241-1bdc-47f4-a986-7cde6617bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params = {\n",
    "    'model': base_model,\n",
    "    'tf': tf,\n",
    "    'train_images': train_images,\n",
    "    'train_labels': train_labels,\n",
    "    'epochs': epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'validation_data': validation_data,\n",
    "    'val_images': validation_data[0],\n",
    "    'val_labels': validation_data[1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34decbbe-f8e1-4ef4-86af-60e01e588249",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_history = base_model_execution(base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879fb69-fa36-48f9-a46f-3d00dfff8a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_training_info(base_model, base_history, video_name, comment, experiment_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099dde2a-f16c-429a-9168-7a391dd68d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167f9d55-9eee-4e2f-9f0f-0c298ce267ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257f6114-26ed-46bc-8b9c-b81c17b51a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec9901a-2ba4-4e0f-b908-d4ace81ab530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a5a27b-7b18-448c-8d4a-e3f91a95275a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
