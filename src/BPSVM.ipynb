{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9e58cf9-c4bb-4027-8799-8763d8bc7f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-11 14:05:35.100341: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-11 14:05:35.138133: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import h5py # for working with HDF5 (Hierarchical Data Format) files\n",
    "import numpy as np\n",
    "import sklearn.svm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from V3.load_calcium_video import load_video_data, load_one_video\n",
    "from V3.align_behavior_to_calcium import align_files_old_labels, align_files_new_labels\n",
    "from V3.class_balance import check_class_imbalance_old, check_class_imbalance_new \n",
    "from V3.preprocessing_model import model_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54bcfbd1-4dcd-4697-8144-c54f89d04c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'experiment_ID' (str)\n"
     ]
    }
   ],
   "source": [
    "comment = \"k-fold-cross validation, multiple videos, new labels\"\n",
    "experiment_ID = '3.4'\n",
    "data_file = 'Animal3learnday8, Animal3Learnday9, Animal3Learnday10'\n",
    "experiment_name = str(data_file)+\"_\"+str(experiment_ID)\n",
    "train_test_split_strategy = \"k-fold\"\n",
    "name = 'BPSVM'\n",
    "model_version = str(name)+'_1'\n",
    "\n",
    "%store experiment_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81c7fd8-4bba-4f5a-96a7-46815726ee35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which labels am I using? Old or New?\n",
    "labels_type = 'new' # or 'old'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3ab3fd-a959-487f-b00b-11cfb8fe6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data? This to find chance performance\n",
    "shuffled_labels = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c241cda-00b2-43c4-b45d-ee51be881094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Am I using one or multiple videos for training?\n",
    "multiple_videos = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a2128d-a3d0-432e-b927-1594f517587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The directory output-svm already exists.\n"
     ]
    }
   ],
   "source": [
    "# Define the name of the output directory\n",
    "output_dir = \"output-svm\"\n",
    "\n",
    "# Check if the output directory already exists\n",
    "if not os.path.exists(output_dir):\n",
    "    # Create the output directory\n",
    "    os.mkdir(output_dir)\n",
    "\n",
    "    # Create the balance, accuracy, loss, and cm directories inside the output directory\n",
    "    os.mkdir(os.path.join(output_dir, \"balance\"))\n",
    "    os.mkdir(os.path.join(output_dir, \"accuracy\"))\n",
    "    os.mkdir(os.path.join(output_dir, \"loss\"))\n",
    "    os.mkdir(os.path.join(output_dir, \"cm\"))\n",
    "    os.mkdir(os.path.join(output_dir, \"architecture\"))\n",
    "    os.mkdir(os.path.join(output_dir, \"pickles\"))\n",
    "else:\n",
    "    print(f\"The directory {output_dir} already exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e733e1-791e-4af0-afd1-ff44601785aa",
   "metadata": {},
   "source": [
    "### Loading Calcium Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39ddd03f-cde9-4f87-880a-a6642734fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # paths to videos\n",
    "# video_paths = [\"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211025_184906_animal3learnday8.nwb\", \n",
    "#                \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211026_142935_animal3learnday9.nwb\", \n",
    "#                \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211027_165052_animal3learnday10.nwb\"]\n",
    "\n",
    "video_path = [\"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211028_181307_animal3learnday11.nwb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a53142b-cf09-4bcb-bc4b-4820e5b08115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the CSV file with the FOV information\n",
    "# fov_info = pd.read_csv('/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/V3/aligned_videos_animal3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e33105-b46a-43fb-bde0-7a60e530910d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20211028_181307_animal3learnday11.nwb recording_20211028_181307-PP-BP-MC\n",
      "(24589, 393, 444)\n"
     ]
    }
   ],
   "source": [
    "video_name_list = []\n",
    "video_data_list = []\n",
    "\n",
    "if multiple_videos == True:\n",
    "    images = load_video_data(video_paths, fov_info, video_name_list, video_data_list)\n",
    "else:\n",
    "    # for one video\n",
    "    images = load_one_video(video_path, video_name_list, video_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd95cc1c-fff1-4419-b8ba-9e6d372e5510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(393, 444)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b1e9b43-7ff5-4340-b999-560fee2b2660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[175, 181, 182, ..., 181, 181, 180],\n",
       "        [170, 174, 173, ..., 177, 176, 179],\n",
       "        [175, 175, 168, ..., 180, 176, 178],\n",
       "        ...,\n",
       "        [180, 182, 175, ..., 170, 173, 167],\n",
       "        [177, 188, 181, ..., 177, 179, 180],\n",
       "        [184, 184, 183, ..., 188, 182, 174]]], dtype=int16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the video has been loaded correctly\n",
    "images[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c4ccdd-446e-47be-9fa0-01211ae37060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of video frames is  24589  and the frame dimensions (height x width) are:  393 X 444\n"
     ]
    }
   ],
   "source": [
    "# Determine the size of the calcium video dataset\n",
    "num_of_frames = images.shape[0]\n",
    "img_height = images.shape[1]\n",
    "img_width = images.shape[2]\n",
    "print(\"The number of video frames is \", num_of_frames, \" and the frame dimensions (height x width) are: \", img_height, \"X\", img_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68ca7d6-1325-42c2-904e-bd84a8db77d7",
   "metadata": {},
   "source": [
    "### Loading Calcium Traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abae8f36-670e-4e1b-9c77-35de535e71f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/animal3.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "613fb769-c0f6-4fe5-b75f-260c903f6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually change from which videos you want to extract calcium traces\n",
    "list_of_traces = []\n",
    "\n",
    "if multiple_videos == True:\n",
    "    with (h5py.File(path, 'r')) as f:\n",
    "        traces_8 = np.array(f['traces/animal3learnday8/deconvolved'])\n",
    "        list_of_traces.append(traces_8)\n",
    "        traces_9 = np.array(f['traces/animal3learnday9/deconvolved'])\n",
    "        list_of_traces.append(traces_9)\n",
    "        traces_10 = np.array(f['traces/animal3learnday10/deconvolved'])\n",
    "        list_of_traces.append(traces_10)\n",
    "else:\n",
    "    with (h5py.File(path, 'r')) as f:\n",
    "        traces = np.array(f['traces/animal3learnday11/deconvolved'])\n",
    "        # list_of_traces.append(traces_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "429125db-4e5a-400c-a8e9-bf57afd9d92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traces = np.concatenate(list_of_traces, axis=1)\n",
    "# print(\"Concatenated traces shape:\", traces.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b73c16b-d406-42b2-9562-0af439cc1763",
   "metadata": {},
   "source": [
    "### Load Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d239e204-c2b8-4f96-b26e-d858b15d41f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if multiple_videos == True:\n",
    "    num_of_videos = 3\n",
    "else:\n",
    "    num_of_videos = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46e90f2e-edea-4104-9cd5-e1892838fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if multiple_videos == True:\n",
    "    bonsai_paths = [\"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/tmaze_2021-10-25T18_48_49.csv\", \n",
    "                   \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/tmaze_2021-10-26T14_29_27.csv\", \n",
    "                   \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/tmaze_2021-10-27T16_50_53.csv\"]\n",
    "else:\n",
    "    bonsai_paths = [\"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/tmaze_2021-10-28T18_13_23.csv\"]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "if multiple_videos == True:\n",
    "\n",
    "    if labels_type == 'old':\n",
    "\n",
    "\n",
    "        behavior_paths = [\"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211025_184906_animal3learnday8.h5\", \n",
    "                       \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211026_142935_animal3learnday9.h5\", \n",
    "                       \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211027_165052_animal3learnday10.h5\"]\n",
    "\n",
    "        df_new_annotations = align_files_old_labels(bonsai_paths, behavior_paths, num_of_videos)\n",
    "    else:\n",
    "        h5_path = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/behavior_segmentation_arrowmaze.h5\"\n",
    "        df_new_annotations = align_files_new_labels(bonsai_paths, num_of_videos, h5_path)\n",
    "\n",
    "        \n",
    "else:\n",
    "    if labels_type == 'old':\n",
    "        behavior_paths = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211028_181307_animal3learnday11.h5\"\n",
    "        df_new_annotations = align_files_old_labels(bonsai_paths, behavior_paths, num_of_videos)\n",
    "\n",
    "\n",
    "    else:\n",
    "        h5_path = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/behavior_segmentation_arrowmaze.h5\"\n",
    "        df_new_annotations = align_files_new_labels(bonsai_paths, num_of_videos, h5_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef1921d-c4df-4ee4-ad95-67d07ef3cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# behavior_paths = [\"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211025_184906_animal3learnday8.h5\", \n",
    "#                \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211026_142935_animal3learnday9.h5\", \n",
    "#                \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/data/20211027_165052_animal3learnday10.h5\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d72b3-de60-4583-99c6-1cb14b2a2426",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45825c79-8900-461c-9eec-bc295672a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new_annotations = align_files(bonsai_paths, behavior_paths, num_of_videos)\n",
    "# df_new_annotations = align_files(bonsai_paths, num_of_videos, h5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0443350-f884-4dae-be3a-12b1e2a64b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new_annotations = df_new_annotations.loc[:, 'state_id']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94885c3c-ee8d-41b0-9dec-0eb248fbc6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_annotations = df_new_annotations.reset_index(drop=True)\n",
    "# df_new_annotations = df_new_annotations.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d081ab-4632-452a-a2a2-9a62b5fe461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_annotations_unique = df_new_annotations.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da76f8c-81b1-4a41-8447-1acb379f86f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_annotations_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59856475-99e9-4449-a097-d70cfff14791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2eb829-a975-4962-9776-1538a3f4e17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"/home/dmc/Desktop/kostas/direct-Behavior-prediction-from-miniscope-calcium-imaging-using-convolutional-neural-networks/src/output-svm/balance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e99a3-3500-40e5-a37b-59c2c05cd4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e079938b-5164-4a89-b4f8-65959ace2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if labels_type == 'old':\n",
    "    class_counts, total_counts = check_class_imbalance_old(df_new_annotations, experiment_ID, save_dir)\n",
    "else:\n",
    "    class_counts, total_counts = check_class_imbalance_new(df_new_annotations, experiment_ID, save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881cf3c-4151-4926-a2e9-94a79b24e16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc77badc-fabe-4813-bddc-bf7f5d87b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_new_annotations.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ff455-c7f0-478e-9406-50ce5607d247",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a3c6c-4db9-442a-8978-dd445bf75a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56c62ad-092e-403f-8718-34b15a417c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036c1f8-7274-486b-abac-00f8f597fa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data verification\n",
    "# plt.plot(traces[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eca329-2151-4d12-bc06-31d5e7d3f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(traces[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23803f-2119-4474-8c05-ba7c51a451db",
   "metadata": {},
   "outputs": [],
   "source": [
    "traces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f6f9c8-8156-43c1-978d-952adbb9e75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(df_new_annotations_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa1fb2b-1cb3-44af-9919-057339eccc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be68997-da53-4be2-9543-e3bc261586c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# traces, labels, num_classes = model_preprocessing(traces, labels, df_new_annotations_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072f18e3-3aed-4ba1-9911-c29f2f9de201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778dcb2f-e11e-4b66-94a0-6f8e373413b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccac99a-ce7c-48cc-8d65-fbcfb19b62d4",
   "metadata": {},
   "source": [
    "## Perform k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d3da1a-5c73-4840-b7eb-55b08ecd5bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySVC = sklearn.svm.LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81036de0-3bdd-46a3-8497-a70e912a0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "from sklearn.svm import LinearSVC\n",
    " \n",
    "mySVC.fit(traces.T, labels)\n",
    "mySVC.predict(traces.T)\n",
    "\n",
    "mySVC = LinearSVC()\n",
    "\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "y_pred = cross_val_predict(mySVC, traces.T, labels, cv=kf)\n",
    "\n",
    "accuracy = accuracy_score(labels, y_pred)\n",
    "print(\"Average accuracy:\", accuracy)\n",
    "\n",
    "y_pred_prob = cross_val_predict(mySVC, traces.T, labels, cv=kf, method='decision_function')\n",
    "log_loss_avg = log_loss(labels, y_pred_prob)\n",
    "print(\"Average log loss:\", log_loss_avg)\n",
    "\n",
    "cm_avg = confusion_matrix(labels, y_pred)\n",
    "print(\"Confusion matrix:\")\n",
    "print(cm_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b67c310-423b-49d7-a8e4-d9cf8c8fde5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the labels\n",
    "shuffled_labels = np.random.permutation(labels)\n",
    "\n",
    "# Use the shuffled labels for cross-validation\n",
    "y_pred = cross_val_predict(mySVC, traces.T, shuffled_labels, cv=kf)\n",
    "\n",
    "# Calculate accuracy using shuffled labels\n",
    "accuracy = accuracy_score(shuffled_labels, y_pred)\n",
    "print(\"Shuffled accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ca384-ecdf-4bc1-9556-f37ed80aa554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80812ccf-fe36-4daa-a551-6188c4bde44b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a850c6-ed86-498a-87d1-997eec23b134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088d12bd-74ea-4338-8350-12aac56e50d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509c4fa-819b-4ce9-97be-e479736f117a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c17699-98f9-44a2-a105-36dbac604be9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_kostas_env",
   "language": "python",
   "name": "new_kostas_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
